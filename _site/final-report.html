<!DOCTYPE html>
<html lang="en-us">
    <head>
        <meta charset="UTF-8">
        <title>Cache Coherence Protocols Analyzer</title>
        <meta name="description" content="An analyzer for Cache Coherence Protocols under varying workloads.<br> Kshitiz Dange (kdange)  |  Yash Tibrewal (ytibrewa)"/>
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#157878">
        <link href='https://fonts.googleapis.com/css?family=Open+Sans:400,700' rel='stylesheet' type='text/css'>
        <link rel="stylesheet" href="/assets/css/style.css?v=d0c643ef9f1678fb753792cd0f56b9a692c4b4d5">
    </head>
    <body>
        <section class="page-header">
            <h1 class="project-name">Cache Coherence Protocols Analyzer</h1>
            <h2 class="project-tagline">An analyzer for Cache Coherence Protocols under varying workloads.<br> Kshitiz Dange (kdange)  |  Yash Tibrewal (ytibrewa)</h2>
            <a href="proposal-page" class="btn">Project Proposal</a>
            <a href="checkpoint-page" class="btn">Checkpoint</a>
            <a href="final-report" class="btn">Final Report</a>
            <a href="authors-page" class="btn">Authors</a>
            
            <a href="http://github.com/kshitizdange/418CacheSim" class="btn">View on GitHub</a>
            
            <a href="http://15418.courses.cs.cmu.edu/spring2017/home" class="btn">15-418 Home</a>
        </section>

        <section class="main-content">
            
<h2 id="1-summary">1. SUMMARY</h2>
<blockquote>
  <p>We have implemented a Cache Simulator for analyzing how different Snooping-Based Cache Coherence Protocols perform
under various workloads. Given any program, we can use our simulator to compare the performance of various protocols,
based on number of Bus Transactions, Memory Requests, Memory Write-Backs and Cache-to-Cache Transfers.</p>
</blockquote>

<h2 id="2-background">2. BACKGROUND</h2>
<blockquote>
  <p>We have studied about different snooping based Cache Coherence Protocols in class. Whenever a processor wants to read
or write something, it tries to use its own cache to avoid having to go to the memory each time (as it’s very slow).
But, when we have multiple processors, we need to synchronize the caches, so that all processors have a coherent view
of memory. For this, one approach is to use a snooping cache, where each cache monitors the memory reads and writes done
by other caches and takes some action based on those requests. MSI is one simple choice but there are other protocols
too which offer different kinds of benefits under specific workloads - MESI, MOSI, MOESI, Dragonfly, etc.
With this project we basically aim to study and demonstrate the advantages of each protocol over the others based on
some real-world, and some synthetic memory traces. We have also implemented a split-bus memory access, so that we can
mimic memory transactions similar to how they happen in real machines, instead of using an atomic bus. This gives us a
clear understanding of the performance of each snooping based protocol.
The inputs for analysis have been derived from programs that are concurrent in nature. We created two kinds of
programs - one based on locks, so that the read/writes are in a FIFO manner; and other based on random (aka wild)
access to the memory, which neither maintain consistency of data nor the order of transactions. We also designed some
artificial test inputs to be able to clearly differentiate the performance of each snooping based protocol.</p>
</blockquote>

<h2 id="3-approach">3. APPROACH</h2>
<blockquote>
  <p>The protocols that we have implemented are: <br />
Write-Invalidate Protocols <br /></p>
  <ol>
    <li>MSI <br />
MSI - Processor Transactions: <br />
<img src="https://upload.wikimedia.org/wikipedia/commons/8/8a/State_diagram_for_processor_transactions.png" alt="alt text" title="MSI Protocol" /> <br />
MSI - Snooped Bus Transactions: <br />
<img src="https://upload.wikimedia.org/wikipedia/commons/e/ea/State_diagram_for_bus_transactions.png" alt="alt text" title="MSI Protocol" /> <br /></li>
    <li>MESI <br />
<img src="http://15418.courses.cs.cmu.edu/spring2017content/lectures/10_cachecoherence1/images/slide_033.jpg" alt="alt text" title="MESI Protocol" /> <br /></li>
    <li>MOSI <br />
MOSI - Processor Transactions: <br />
<img src="https://upload.wikimedia.org/wikipedia/commons/4/4d/MOSI_Processor_Transactions.png" alt="alt text" title="MOSI-1 Protocol" /> <br />
MOSI - Snooped Bus Transactions: <br />
<img src="https://upload.wikimedia.org/wikipedia/commons/5/50/MOSI_Bus_Transactions_Updated.png" alt="alt text" title="MOSI-2 Protocol" /> <br /></li>
    <li>MOESI <br />
<img src="http://wiki.expertiza.ncsu.edu/images/thumb/4/4e/MOESIfig.jpg/450px-MOESIfig.jpg" alt="alt text" title="MOESI Protocol" /> <br />
Write-Update Protocols <br /></li>
    <li>Dragonfly (write-back update) <br />
<img src="http://15418.courses.cs.cmu.edu/spring2017content/lectures/10_cachecoherence1/images/slide_038.jpg" alt="alt text" title="Dragon Protocol" /> <br />
All of these protocols use write-allocate write-back caching. <br />
      <ul>
        <li>Image Sources: <br />
MSI: https://en.wikipedia.org/wiki/MSI_protocol <br />
MESI: http://15418.courses.cs.cmu.edu/spring2017/lecture/cachecoherence1 <br />
MOSI: https://en.wikipedia.org/wiki/MOSI_protocol <br />
MOESI: http://wiki.expertiza.ncsu.edu/images/thumb/4/4e/MOESIfig.jpg/450px-MOESIfig.jpg <br />
Dragon: http://15418.courses.cs.cmu.edu/spring2017/lecture/cachecoherence1 <br /></li>
      </ul>
    </li>
  </ol>
</blockquote>

<h3 id="31-working">3.1. Working:</h3>
<blockquote>
  <p>We use Intel’s pintool to instrument programs and generate memory traces for them. For this, we wrote our own pintool,
which for each instruction, checks whether it has a memory access or not. If it has a memory access, then at runtime we
record the following information: <br />
1. Whether the access is a read or a write <br />
2. The memory address for the load/store <br />
3. The thread-ID for the thread which performed the load/store <br /> <br />
This is saved in a file in the following format : <br /></p>
  <div class="language-javascript highlighter-rouge"><pre class="highlight"><code><span class="p">[</span><span class="nx">Thread</span><span class="o">-</span><span class="nx">ID</span><span class="p">]</span> <span class="p">[</span><span class="nx">R</span><span class="o">/</span><span class="nx">W</span><span class="p">]</span> <span class="p">[</span><span class="nx">Memory_Address</span><span class="p">]</span>
</code></pre>
  </div>
  <p>Example: <br /></p>
  <div class="language-javascript highlighter-rouge"><pre class="highlight"><code><span class="mi">0</span> <span class="nx">R</span> <span class="mh">0x1024</span>
<span class="mi">0</span> <span class="nx">W</span> <span class="mh">0x1024</span>
<span class="mi">1</span> <span class="nx">R</span> <span class="mh">0x1088</span>
<span class="mi">1</span> <span class="nx">W</span> <span class="mh">0x1088</span>
<span class="mi">2</span> <span class="nx">R</span> <span class="mh">0x1152</span>
</code></pre>
  </div>
  <p>For improved analysis of a program, we have written another pintool which allows demarcating the code which we want to
 analyze using the simulator. This is to help in the scenario, where a program is very large and there are only specific
  parts of the program that we want to analyze. We do this by calling two dummy functions: dummy_instr_start() and
   dummy_instr_end(). The pintool recognizes calls to these functions, so when it sees a dummy_instr_start(), it
   starts recording memory accesses and on dummy_instr_end(), it stops recording them. <br />
Once we have the memory trace generated by one of the pintools, we pass it to our Cache Simulator. <br /></p>
  <h3 id="32-cache-simulator-design">3.2. Cache Simulator Design:</h3>
  <p>Our Cache Simulator allows varying the following parameters: <br /></p>
  <div class="language-javascript highlighter-rouge"><pre class="highlight"><code><span class="o">-</span><span class="nx">c</span> <span class="nb">Number</span> <span class="nx">of</span> <span class="nx">Processor</span> <span class="nx">Cores</span><span class="o">/</span><span class="nx">Caches</span>
<span class="o">-</span><span class="nx">s</span> <span class="nx">Cache</span> <span class="nx">Size</span> <span class="p">(</span><span class="k">in</span> <span class="nx">MB</span><span class="p">)</span>
<span class="o">-</span><span class="nx">a</span> <span class="nx">Set</span> <span class="nx">Associativity</span>
<span class="o">-</span><span class="nx">p</span> <span class="nx">Cache</span> <span class="nx">Coherence</span> <span class="nx">Protocol</span> <span class="nx">to</span> <span class="nx">use</span> <span class="p">(</span><span class="nx">MSI</span><span class="o">/</span><span class="nx">MESI</span><span class="o">/</span><span class="nx">MOSI</span><span class="o">/</span><span class="nx">MOESI</span><span class="o">/</span><span class="nx">Dragon</span><span class="p">)</span>
<span class="o">-</span><span class="nx">t</span> <span class="nx">The</span> <span class="nx">trace</span> <span class="nx">file</span> <span class="nx">to</span> <span class="nx">use</span>
</code></pre>
  </div>
  <ul>
    <li>At initialization, we create caches for each processor, and we create two pThreads for each cache. One thread is
responsible for handling requests from the processor and initiating bus transactions if necessary (processor
transactions), while the other thread is responsible for responding to bus transactions (snooped bus transactions). For
accesses to memory, we have simulated a split-transaction bus. We create a pThread to act as the memory controller. We
have also added a small delay(of the order of couple ms), so that each memory request has some considerable latency
associated with it. This also means that while a memory request is pending, another cache might request the same
cacheline. This causes some interesting correctness issues that we will discuss later. <br /></li>
    <li>The high level workflow of our simulator is as follows: <br />
The main thread is responsible for reading the memory trace and instructing the appropriate caches to perform the
required memory read/write. This is implemented using a signalling mechanism (mutex and condition variables). <br /></li>
    <li>When a cache worker receives the signal for the memory access, it checks the state of the cacheline which has the
address and executes the protocol transitions if any. If the transition requires a snooping bus transaction, it
contends for the bus and broadcasts the action it wants to perform. The snooping threads for the other caches read
this action and depending on the protocol, they might change the status of the cache line, invalidate it, flush it to
memory, etc. If the cache worker who is performing the action does not have the cacheline in a valid state, one of the
other caches can place the data on the bus for this cache to read. Once the snooping is done, the cache worker might be
done with the handling of the memory access, or it might need to go to memory to fetch the cacheline (if no other cache
had the cacheline). In this case, we use the split transaction bus to request the cacheline from memory. <br /></li>
    <li>This continues till all caches are done with the memory accesses they were required to perform. <br />
Based on the actions that a cache performed, we update the number of snooping bus transactions, memory requests,
memory writebacks and cache to cache transfers. <br /></li>
  </ul>
</blockquote>

<h3 id="33-metrics-used-for-comparison">3.3. Metrics Used for Comparison</h3>
<blockquote>
  <ol>
    <li>Number of Snooping Bus Transactions - The number of bus transactions that the protocol implementation requires
for the program. <br /></li>
    <li>Number of Memory requests - The number of cacheline loads that have to be served by main memory (and not another
cache).  <br /></li>
    <li>Number of Memory writebacks - The number of times any cacheline has to be written back to main memory. <br /></li>
    <li>Number of Cache to Cache Transfers - The number of cacheline loads that are served by another cache. <br />
 <br /> <br />
Ideally, we want as few bus transactions, memory requests, memory write-backs or cache to cache transfers as possible
because all of them will have some amount of latency associated with them. If it is a choice between a memory request
and a cache to cache transfer, we always prefer the latter, because a memory request will have much higher latency
compared to getting data from another cache. <br /></li>
  </ol>
</blockquote>

<h3 id="34-interesting-synchronization-and-implementation-issues">3.4. Interesting Synchronization and Implementation Issues:</h3>
<blockquote>
  <p>As described earlier, we create separate threads to simulate various parts of the cache. To maintain and ensure
correctness, there are certain issues we need to take care of:</p>
  <h4 id="341-split-transaction-bus">3.4.1. Split Transaction Bus</h4>
  <p>Having a split transaction bus means that when there is a request from one cache pending, another cache can request
load of the same cacheline. In this case, the memory does not need to service the same request twice. It just needs to
provide the data for the cacheline to both the caches, or in other words, both the caches need to be listening for the
memory’s servicing of the same request. For implementing this, we create a separate condition variable for each
request. When a cache needs something serviced from memory, it first checks whether the access already exists in the
request table. If it already exists, instead of creating another memory request in the table, it simply waits on the
condition variable of the existing request. When the memory worker is done servicing the request, it performs a
broadcast on the condition variable associated with the request, so that all caches that were waiting for that request
can continue with their work.</p>
  <h4 id="342-cache-worker-and-snooping-worker">3.4.2. Cache Worker and Snooping Worker</h4>
  <p>We have two workers (pThreads) for each cache. One for servicing load/store requests from the processor and one for
servicing for snooping bus transactions. Both these threads require concurrent access to the same cache, and hence the
accessed need to be synchronized. Our implementation uses a single copy of the cache with pthread mutexes for
synchronization.</p>
  <h4 id="343-snooping-bus">3.4.3. Snooping Bus</h4>
  <p>The current implementation of the snooping bus uses pthread mutices and condition variables. The order in which caches
gain access to the bus is completely dependent on the implementation of pthread mutex and condition variables. Based
on our implementation, we can easily enforce a specific ordering on the arbitration, but we decided to use the simple
default implementation. To explain in brief, we have a mutex for getting access to the snooping bus for broadcasting
actions. Another mutex is required for other snooping caches to respond to this action. This also involves the
snooping caches informing the cache worker whether the cacheline would be in the exclusive or shared state, or if the
cache worker does not have the cacheline, whether the snooping cache can provide the data for the cacheline. A snooping
caches can also NACK the transaction, if its own cache has a conflicting pending transaction that is waiting to be
serviced by the split transaction bus. <br /></p>
</blockquote>

<h3 id="35-protocols-low-level-design-choices">3.5. Protocols Low Level Design Choices:</h3>
<blockquote>
  <p>We have designed all the aforementioned protocols so that a cache miss will try to be serviced from another cache
(if a cache already has the data). This reduces the number of memory requests required. <br />
In MOSI and MOESI implementations, memory writebacks only happen when a cacheline in Modified or Owner state is
evicted. If a cacheline is invalidated due to the protocol, the cache transfers the cacheline to the new owner of the
cacheline. (We deem the cache which has a line in the Modified or Owner state to be the owner.) This enhances the
effect of the additional Owner state. <br />
In our Dragon implementation, when a line is in the SharedClean or SharedModified state and tries to perform a write,
we first check whether it is the only cache holding the line or not. If it is the only one holding the cacheline, then
instead of having to perform a BusUpdate and moving to the SharedModified state, it can simply move to the Modified
state. This helps in the case where other caches have evicted that line causing only one cache to have the line. This
saves on unnecessary bus transactions.</p>
</blockquote>

<h3 id="40-protocols-low-level-design-choices">4.0. Protocols Low Level Design Choices:</h3>
<blockquote>
  <p>We have designed all the aforementioned protocols so that a cache miss will try to be serviced from another cache
(if a cache already has the data). This reduces the number of memory requests required. <br />
In MOSI and MOESI implementations, memory writebacks only happen when a cacheline in Modified or Owner state is
evicted. If a cacheline is invalidated due to the protocol, the cache transfers the cacheline to the new owner of the
cacheline. (We deem the cache which has a line in the Modified or Owner state to be the owner.) This enhances the
effect of the additional Owner state. <br />
In our Dragon implementation, when a line is in the SharedClean or SharedModified state and tries to perform a write,
we first check whether it is the only cache holding the line or not. If it is the only one holding the cacheline, then
instead of having to perform a BusUpdate and moving to the SharedModified state, it can simply move to the Modified
state. This helps in the case where other caches have evicted that line causing only one cache to have the line. This
saves on unnecessary bus transactions <br /></p>
  <h4 id="nack">NACK</h4>
  <p>As mentioned earlier, our choice of implementation for the snooping bus and the split transaction bus can
cause a snooping bus request to conflict with a pending split transaction bus. For example, while a memory load for a
cacheline is pending in the request table from a read issued by one processor, another cache can be requesting
exclusive access to the same cacheline on the snooping bus. In this case, if the cache with the pending request allows
the new request to go ahead, it will have to retry its memory load at a later time. This can cause a livelock, if the
two caches keep retrying and giving way to each other. To avoid this, if a snooping cache detects a conflicting action
on the snooping bus, it NACKs the action, which causes the cache worker to retry the transaction at a later time. This
avoids the livelock issue and ensures completion.</p>
</blockquote>

<h2 id="5-platform-choice">5. PLATFORM CHOICE</h2>
<blockquote>
  <p>We have used C++ as the programming language, as this project mainly involves being able to read the
memory traces from input files and dumping them into an output file. This was easy to achieve in C++. <br />
For generating memory traces, we have modified and used Intel’s pintool.</p>
</blockquote>

<h2 id="6-schedule">6. SCHEDULE</h2>
<blockquote>
  <p>Apr 11 - Apr 17 - Implement a simple LRU cache for a single processor <br />
Apr 18 - Apr 24 - Add support for cache coherence protocols - MSI, MESI <br />
Apr 25 - May 01 - Add additional protocols - MOSI, MOESI, Dragon, Firefly, etc. <br />
May 02 - May 07 - Generate different types of memory workloads and Perform Analysis <br />
May 09 - May 11 - Project Presentation Preparation <br /></p>
</blockquote>



            <footer class="site-footer">
                
                <span class="site-footer-owner"><a href="http://github.com/kshitizdange/418CacheSim">418CacheSim</a>
                            is maintained by <a href="mailto:kdange@cmu.edu">Kshitiz Dange </a> and
                            <a href="mailto:ytibrewa@andrew.cmu.edu">Yash Tibrewal </a></span>
                
                <span class="site-footer-credits">This page was generated by <a href="https://pages.github.com">GitHub Pages</a>.</span>
            </footer>
        </section>

        
    </body>
</html>
